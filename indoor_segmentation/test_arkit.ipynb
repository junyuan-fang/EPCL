{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopen3d\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mo3d\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;66;03m# why is it located here?\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'open3d'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import open3d as o3d\n",
    "import torch # why is it located here?\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import pdb\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from model import get as get_model\n",
    "from model.utils.configs import Config\n",
    "from model.utils.common_util import AverageMeter, intersectionAndUnion, find_free_port\n",
    "# from model import get as get_model\n",
    "# from dataset import get as get_dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed=0\n",
    "pl.seed_everything(seed) # , workers=True\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "\n",
    "def read_txt(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [int(x.strip()) for x in lines]\n",
    "    return lines\n",
    "\n",
    "#parser = my_args()\n",
    "args = Config()\n",
    "\n",
    "    # ------------\n",
    "    # randomness or seed\n",
    "    # ------------\n",
    "torch.backends.cudnn.benchmark = args.cudnn_benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load check point for the model\n",
    "from importlib import import_module\n",
    "args.load_model =\"/home/fangj1/Code/Vision-Language-on-3D-Scene-Understanding/EPCL/indoor_segmentation/checkpoints/epoch=062--mIoU_val=0.6972--.ckpt\"\n",
    "args.on_train = False\n",
    "print('ckpt best. args.load_model=[{}]'.format(args.load_model))\n",
    "assert args.load_model is not None, 'why did you come?'\n",
    "print(args.transdown)\n",
    "model = get_model(args.model).load_from_checkpoint(\n",
    "    os.path.join(args.MYCHECKPOINT, args.load_model), \n",
    "    args=args).to(device) # args.strict_load\n",
    "\n",
    "model.eval()\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process arkit data\n",
    "in original model need (n, 3), (n, c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data loader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "class ArkitDataLoader(Dataset):\n",
    "    def __init__(self, scene_path , query_path = None, mask_path = None):\n",
    "        \"\"\"\n",
    "        初始化点云数据集\n",
    "        :param ply_files: PLY文件的列表\n",
    "        \"\"\"\n",
    "        self.scene_path = scene_path\n",
    "        self.query_path = query_path\n",
    "        self.mask_path = mask_path\n",
    "        self.ply_list = []  # 先初始化列表\n",
    "        self.query_list = []\n",
    "        self.mask_list = []\n",
    "        self.scene_id = None\n",
    "        \n",
    "        # 然后加载数据\n",
    "        self.load_ply_list()\n",
    "        self.load_query_list()\n",
    "        self.load_mask_list()\n",
    "        \n",
    "    def load_ply_list(self):\n",
    "        \"\"\"\n",
    "        加载PLY文件列表\n",
    "        \"\"\"\n",
    "        # 读取PLY文件列表\n",
    "        self.ply_list = sorted(glob.glob(os.path.join(self.scene_path, '4*/*.ply')))\n",
    "        #print(\"Loaded PLY files:\", self.ply_list)\n",
    "    def load_query_list(self):\n",
    "        if self.query_path is not None:\n",
    "            # 加载CSV文件\n",
    "            df = pd.read_csv(self.query_path)\n",
    "\n",
    "            # 按照某个列的值进行排序\n",
    "            df_sorted = df.sort_values(by='video_id')\n",
    "\n",
    "            # 获取排序后的另一个列的值\n",
    "            self.query_list = df_sorted['query'].values\n",
    "            # # 输出获取的值\n",
    "            # print(self.query_list)\n",
    "            \n",
    "    def load_mask_list(self):\n",
    "        if self.mask_path is not None:\n",
    "            self.mask_list = sorted(glob.glob(os.path.join(self.mask_path, '*.txt')))\n",
    "            #print(self.mask_list)\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        数据集中的样本数\n",
    "        \"\"\"\n",
    "        return len(self.ply_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        读取单个点云文件，并返回其数据\n",
    "        :param idx: 索引\n",
    "        \"\"\"\n",
    "        self.scene_id = self.mask_list[idx].split('/')[-1].split('_')[0]\n",
    "        #print(self.ply_list[idx].split('/')[-1].split('_')[0])\n",
    "        # 加载点云文件\n",
    "        pcd = o3d.io.read_point_cloud(self.ply_list[idx])\n",
    "\n",
    "        # 获取坐标\n",
    "        coordinates = np.asarray(pcd.points, dtype=np.float32)\n",
    "\n",
    "        # 获取特征，这里假设使用颜色作为特征\n",
    "        if pcd.colors:\n",
    "            features = np.asarray(pcd.colors, dtype=np.float32)  # RGB颜色\n",
    "        else:\n",
    "            features = np.zeros((coordinates.shape[0], 3), dtype=np.float32)  # 如果没有颜色，使用零填充\n",
    "\n",
    "        \n",
    "        #mask\n",
    "        if self.mask_path is not None:\n",
    "            mask = read_txt(self.mask_list[idx])\n",
    "        # 将数据转换为torch tensors\n",
    "        mask = torch.tensor(mask).unsqueeze(1)\n",
    "        coordinates = torch.from_numpy(coordinates)\n",
    "        features = torch.from_numpy(features)\n",
    "\n",
    "        #return {'coord': coordinates, 'feat': features, 'prompt': self.query_list[idx], 'target': mask}\n",
    "        return coordinates, features, self.query_list[idx], mask\n",
    "# def collate_fn(batch):\n",
    "#     max_points = max([sample['coord'].shape[0] for sample in batch])\n",
    "#     feature_dim = batch[0]['feat'].shape[1]\n",
    "\n",
    "#     batch_coordinates = torch.zeros(len(batch), max_points, 3, device=device)\n",
    "#     batch_features = torch.zeros(len(batch), max_points, feature_dim, device=device)\n",
    "#     batch_prompts = []\n",
    "#     batch_masks = torch.zeros(len(batch), max_points, 1,device=device)\n",
    "\n",
    "#     for i, sample in enumerate(batch):\n",
    "#         num_points = sample['coord'].shape[0]\n",
    "#         batch_coordinates[i, :num_points] = sample['coord'].to(device)\n",
    "#         batch_features[i, :num_points] = sample['feat'].to(device)\n",
    "#         batch_prompts.append(sample['prompt'])\n",
    "#         batch_masks[i, :num_points] = sample['target'].to(device)\n",
    "    \n",
    "#     offset, count = [], 0\n",
    "#     for item in max_points: # len of pc\n",
    "#         count += item.shape[0]\n",
    "#         offset.append(count)   \n",
    "#     return {\n",
    "#         'coord': batch_coordinates,\n",
    "#         'feat': batch_features,\n",
    "#         'offset': torch.IntTensor(batch_offsets),\n",
    "#         'prompt': batch_prompts,\n",
    "#         'target': batch_masks\n",
    "#     }\n",
    "def TrainValCollateFn(batch):\n",
    "    coord, feat, prompt, mask = list(zip(*batch))\n",
    "    offset, count = [], 0\n",
    "    for item in coord: # len of pc\n",
    "        count += item.shape[0]\n",
    "        offset.append(count)\n",
    "    \n",
    "    print(\"Coordinates type:\", type(coord[0]))  # Check the type of the first coordinate set\n",
    "    print(\"Features type:\", type(feat[0]))      # Check the type of the first features set\n",
    "    print(\"Mask type:\", type(mask[0]))          # Check the type of the first mask\n",
    "    print(\"Offset type:\", type(offset[0]))      # Check the type of the first offset\n",
    "    \n",
    "    data_dict = \\\n",
    "        {\n",
    "            'coord': torch.cat(coord).to(device),\n",
    "            'feat': torch.cat(feat).to(device),\n",
    "            'target': torch.cat(mask).to(device),\n",
    "            'prompt': list(prompt),\n",
    "            'offset': torch.IntTensor(offset).to(device),\n",
    "        }\n",
    "    return data_dict\n",
    "dataset = ArkitDataLoader(args.arkit_train_root,args.development_query_root,args.development_mask_root)\n",
    "#data_loader = DataLoader(dataset, batch_size= args.train_batch, collate_fn=TrainValCollateFn)\n",
    "data_loader = DataLoader(dataset, batch_size= 1, collate_fn=TrainValCollateFn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test input with Arkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cuda_memory_usage(device_id=0):\n",
    "    t = torch.cuda.get_device_properties(device_id).total_memory\n",
    "    r = torch.cuda.memory_reserved(device_id) \n",
    "    a = torch.cuda.memory_allocated(device_id)\n",
    "    f = r - a  # free inside reserved\n",
    "\n",
    "    print(f\"CUDA Device ID: {device_id}\")\n",
    "    print(f\"Total memory: {t / 1e9:.2f} GB\")\n",
    "    print(f\"Reserved memory: {r / 1e9:.2f} GB\")\n",
    "    print(f\"Allocated memory: {a / 1e9:.2f} GB\")\n",
    "    print(f\"Free (inside reserved): {f / 1e9:.2f} GB\")\n",
    "data_iterator = iter(data_loader)\n",
    "\n",
    "# 获取第一个元素\n",
    "first_batch = next(data_iterator)\n",
    "model(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "cls = nn.Sequential(\n",
    "    nn.Linear(32, 128), \n",
    "    nn.BatchNorm1d(128), \n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 512), \n",
    "    nn.BatchNorm1d(512), \n",
    "    nn.ReLU(inplace=True))\n",
    "cls = cls.to(device)\n",
    "\n",
    "\n",
    "#model.model.cls =cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_ftrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
